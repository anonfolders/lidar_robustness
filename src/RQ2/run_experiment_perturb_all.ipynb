{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../../trajectron')\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import dill\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.patheffects as pe\n",
    "from helper import *\n",
    "import visualization\n",
    "import statistics\n",
    "from collections import Counter\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load nuScenes SDK and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuScenes_data_path = 'v1.0-trainval'    # Data Path to nuScenes data set \n",
    "nuScenes_devkit_path = './devkit/python-sdk/'\n",
    "sys.path.append(nuScenes_devkit_path)\n",
    "from nuscenes.map_expansion.map_api import NuScenesMap\n",
    "nusc_map = NuScenesMap(dataroot=nuScenes_data_path, map_name='boston-seaport')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Encoding Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../processed/nuScenes_test_full.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    eval_env = dill.load(f, encoding='latin1')\n",
    "eval_scenes = eval_env.scenes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = 6\n",
    "log_dir = './models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ROI in nuScenes Map\n",
    "x_min = 773.0\n",
    "x_max = 1100.0\n",
    "y_min = 1231.0\n",
    "y_max = 1510.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = ['drivable_area',\n",
    "          'road_segment',\n",
    "          'lane',\n",
    "          'ped_crossing',\n",
    "          'walkway',\n",
    "          'stop_line',\n",
    "          'road_divider',\n",
    "          'lane_divider']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using velocity output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERTURBATIONS = {\n",
    "    'x_q1':(-0.0398, 0.0071),\n",
    "    'x_q3':(0.0008, -0.0213),\n",
    "    'y_q1':(-0.0519, -0.0247),\n",
    "    'y_q3':(-0.0613, 0.0152),\n",
    "    'x_uf':(0.0617, -0.0283),\n",
    "    'x_lf':(-0.1018, -0.0426),\n",
    "    'y_uf':(-0.0471, 0.0752),\n",
    "    'y_lf':(-0.0250, -0.0852),\n",
    "    'x_out':(-0.3349, -0.5756),\n",
    "    'y_out':(-0.1250, -0.1358),\n",
    "    'x_min':(-5.8995, -3.1643),\n",
    "    'xy_max':(0.5272, 0.4045),\n",
    "    'y_min':(-5.3667, -3.2429),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "for sid, scene in enumerate(eval_env.scenes):\n",
    "    for ni, n in enumerate(scene.nodes):\n",
    "        if str(n.id) != 'ego':\n",
    "            counter.append(str(n.type))\n",
    "print(f'Obstacle count {Counter(counter)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(log_dir, 'vel_ee') \n",
    "eval_stg_vel, hyp = load_model(model_dir, eval_env, ts=12)\n",
    "\n",
    "print(f'Number of scenes = {len(eval_scenes)}')\n",
    "scenes = eval_scenes\n",
    "ph = 6\n",
    "with torch.no_grad():\n",
    "    timestep = np.array([2])\n",
    "\n",
    "    output = {}\n",
    "    for perturbation, pvalue in PERTURBATIONS.items():\n",
    "        print(f'In round {perturbation}')\n",
    "        for sid, scene in enumerate(scenes):\n",
    "            scene_perturb = deepcopy(scene)\n",
    "            for ni, n in enumerate(scene.nodes):\n",
    "                if str(n.id) != 'ego':\n",
    "                    to_del = -1\n",
    "                    for di, _ in enumerate(n.data.data):\n",
    "                        # modify all\n",
    "                        scene_perturb.nodes[ni].data.data[di][0] += pvalue[0]\n",
    "                        scene_perturb.nodes[ni].data.data[di][1] += pvalue[1]\n",
    "\n",
    "            predictions_mm = eval_stg_vel.predict(scene,\n",
    "                                                timestep, ph,\n",
    "                                                num_samples=1,\n",
    "                                                z_mode=True, gmm_mode=True)\n",
    "\n",
    "            predictions_mm_perturb = eval_stg_vel.predict(scene_perturb,\n",
    "                                                        timestep, ph,\n",
    "                                                        num_samples=1,\n",
    "                                                        z_mode=True, gmm_mode=True)   \n",
    "\n",
    "            # values will always be equal to timestep above\n",
    "            pkey = list(predictions_mm_perturb.keys())[0]\n",
    "            output[scene.name] = {}\n",
    "            for node in predictions_mm_perturb[pkey].keys():\n",
    "                output[scene.name][str(node)] = {\n",
    "                    'original': predictions_mm[pkey][node].tolist(),\n",
    "                    'perturbed': predictions_mm_perturb[pkey][node].tolist()\n",
    "                }\n",
    "        # saving data\n",
    "            if (sid + 1) % 20 == 0:\n",
    "                print(f'Saving at index {sid}, scene {scene.name}')\n",
    "                with open(f'perturbated_results/change_all/{perturbation}/saved_at_{scene.name}.json', 'w') as fd:\n",
    "                    json.dump(output, fd)\n",
    "        with open(f'perturbated_results/change_all/{perturbation}/saved_final.json', 'w') as fd:\n",
    "            json.dump(output, fd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(data_baseline, perturbation, perturbation_type):\n",
    "\n",
    "    final_file = f'perturbated_results/{perturbation_type}/{perturbation}/saved_final.json'\n",
    "    if perturbation_type == 'remove_once':\n",
    "        final_file = f'perturbated_results/{perturbation_type}/saved_final.json'\n",
    "    with open(final_file, 'r') as fd:\n",
    "        data = json.loads(fd.read())\n",
    "\n",
    "        ade_x_2 = []\n",
    "        ade_y_2 = []\n",
    "        ade_dist_2 = []\n",
    "\n",
    "        fde_x_2 = []\n",
    "        fde_y_2 = []\n",
    "        for ts, _ in data.items():\n",
    "            # print(ts)\n",
    "            for obs, _ in data[ts].items():\n",
    "                if 'ego' not in obs:\n",
    "                # if 'PEDESTRIAN' in obs:\n",
    "                # if 'VEHICLE' in obs:\n",
    "                    orig = data_baseline[ts][obs]['original'][0][0]\n",
    "                    pert = data[ts][obs]['perturbed'][0][0]\n",
    "                    # ade\n",
    "                    ade_dist_2.append(mean_squared_error(pert, orig))\n",
    "\n",
    "                    orig_x = [i[0] for i in orig]\n",
    "                    pert_x = [i[0] for i in pert]\n",
    "\n",
    "                    orig_y = [i[1] for i in orig]\n",
    "                    pert_y = [i[1] for i in pert]\n",
    "\n",
    "                    ade_x_2.append(mean_squared_error(orig_x, pert_x, squared=False))\n",
    "                    ade_y_2.append(mean_squared_error(orig_y, pert_y, squared=False))\n",
    "\n",
    "                    # fde\n",
    "                    orig_x = [orig[-1][0]]\n",
    "                    pert_x = [pert[-1][0]]\n",
    "\n",
    "                    orig_y = [orig[-1][1]]\n",
    "                    pert_y = [pert[-1][1]]\n",
    "                    fde_x_2.append(mean_squared_error(orig_x, pert_x, squared=False))\n",
    "                    fde_y_2.append(mean_squared_error(orig_y, pert_y, squared=False))\n",
    "\n",
    "        print(perturbation, round(np.quantile(ade_x_2, .99, interpolation='nearest'), 4), round(np.quantile(ade_y_2, .99, interpolation='nearest'), 4))\n",
    "        print(perturbation, round(np.quantile(fde_x_2, .99, interpolation='nearest'), 4), round(np.quantile(fde_y_2, .99, interpolation='nearest'), 4))\n",
    "\n",
    "data_baseline = None\n",
    "\n",
    "with open(f'perturbated_results/change_all/xy_max/saved_final.json', 'r') as fd: \n",
    "    data_baseline = json.loads(fd.read())\n",
    "\n",
    "for perturbation_type in ['change_all']:\n",
    "    print(perturbation_type, 'ade', 'fde')\n",
    "    for perturbation, _ in PERTURBATIONS.items():\n",
    "        compute_error(data_baseline, perturbation, perturbation_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (Trajectron++)",
   "language": "python",
   "name": "trajectronpp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
